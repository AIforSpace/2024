---
layout: project
urltitle:  "AI4Space 2024"
title: "AI4Space 2024"
categories: cvpr, workshop, artificial intelligence, computer vision, space
permalink: /
favicon: /static/img/ico/favicon.png
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row header-row" id="home">
  <div class="col-xs-12 header-img">  
    <center><h1 style="font-size:60px">AI4Space 2024</h1></center>
    <center><br></center>
    <center><br></center>
    <br>
    <br>
    <br>
    <center><h3 style="color:white">3rd Workshop on AI for Space</h3></center>
    <center><h3 style="color:white">In conjunction with <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a></h3></center>    
    <center><h3 style="color:white">Time/Date: 9am-12:15pm, June 17, 2024</h3></center>
    <center><h3 style="color:white">Venue: Seattle Convention Center</h3></center>
    <br>
  </div>
</div>

<hr>

<div class="row">
  <div class="col-xs-12">
    <h5 style="color:red"><center><a href="#call">CALL FOR PAPERS</a> --- New paper submission deadline: March 8, 2024</center></h5>
    <h5 style="color:red"><center><a href="#challenge">CALL FOR CHALLENGE PARTICIPANTS</a></center></h5>
  </div>
</div>

<hr>

<div class="row">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
        <p>The space sector is experiencing significant growth. Currently planned activities and utilisation models also greatly exceed the scope, ambition and/or commercial value of space missions in the previous century, e.g., autonomous satellites for earth observation, on-orbit servicing, intelligent rovers for planetary exploration, and space traffic management and debris mitigation. Achieving these ambitious goals requires surmounting non-trivial technical obstacles. AI4Space focuses on the role of AI, particularly computer vision and machine learning, in helping to solve those technical hurdles. The workshop will highlight the space capabilities that draw from and/or overlap significantly with vision and learning research, outline the unique difficulties presented by space applications to vision and learning, and discuss recent advances towards overcoming those obstacles.
        </p>
  </div>
</div>

<div class="row" id="call">
<hr>
<br>
</div>

<div class="row">
  <div class="col-xs-12">
    <h2>Call for Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      We solicit papers for AI4Space. The general emphasis of AI4Space is vision and learning algorithms for autonomous space systems, which operate in the Earth’s orbital regions, cislunar orbit, planetary bodies (e.g., the moon, Mars and asteroids), and interplanetary space. Emphasis is also placed on novel sensors and processors for vision and learning in space, mitigating the challenges of the space environment towards vision and learning (e.g., radiation, extreme temperatures), and fundamental difficulties in vision and learning for space (e.g., lack of training data, unknown operating environments).
    </p>
    <p>
    A specific list of topics is as follows:
    <ul>
      <li>Vision and learning for spacecraft navigation and operations (e.g., rendezvous, proximity operations, docking, space maneuvers, entry descent landing).</li>
      <li>Vision and learning for space robots (e.g., rovers, UAVs, UGVs, UUWs) and multi-agent systems.</li>
      <li>Mapping and global positioning on planetary bodies (moon, Mars, asteroids), including celestial positioning.</li>
      <li>Onboard AI for Earth observation applications (e.g. near-real-time disaster monitoring, distributed learning on satellites, tip and cue satellite-based systems).</li>
      <li>Onboard AI for satellite operations (e.g. AI-based star trackers, fault detection isolation and recovery).</li>
      <li>Space debris monitoring and mitigation.</li>
      <li>Sensors for space applications (e.g., optical, multispectral, lidar, radar, neuromorphic).</li>
      <li>Onboard compute hardware for vision and learning (e.g., neural network accelerators, neuromorphic processors).</li>
      <li>Mitigating challenges of the space environment (e.g., radiation, thermal) to vision and learning systems.</li>
      <li>Datasets, transfer learning and domain gap.</li>
    </ul>
    </p>

    <p>
  Things to note:
      <ul>
      <li>Papers will be fully peer reviewed and accepted papers will be published in the proceedings of CVPR 2024 Workshops.</li>
      <li>AI4Space follows the <a href="https://cvpr.thecvf.com/Conferences/2024/AuthorGuidelines">submission policies</a> of CVPR 2024. An implication is that submissions to AI4Space should be sufficiently original works not under consideration/reviewing in other venues.</li>
      <li>Consistent with the submission policy, we highly encourage submission of papers relevant to AI4Space but are rejected from the main CVPR conference (decisions on Feb 27---before the AI4Space submission deadline on March 1).</li>
      <li><b>Accepted AI4Space papers are also expected to be presented in person at the workshop</b>, which will be co-located with <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a>.</li>
      <li>If you require a formal invitation letter to facilitate your travel to CVPR 2024 in Seattle, please visit the <a href="https://cvpr.thecvf.com/Conferences/2024">main conference page</a>.</li>
      <li>All papers published via this workshop must be aimed towards the peaceful usage of AI for space.</li>
      </ul>
      </p>
    
    <h3>Submission</h3>  
    <p>
      Submissions must be in the <a href="https://github.com/cvpr-org/author-kit/releases">CVPR format</a> and are limited to 8 pages excluding references.
      Please refer to the main conference's <a href="https://cvpr.thecvf.com/Conferences/2024/AuthorGuidelines">submission guildelines</a> for more details, and do not hesitate to contact the lead organiser <a href="https://cs.adelaide.edu.au/~ssl/author/tat-jun-chin/">Tat-Jun Chin</a> if you have any questions.
  </p>
    <p>  
        Paper submission will be conducted through <a href="https://cmt3.research.microsoft.com/AI4Space2024/">CMT3</a>. See <a href="#dates"><b>key dates</b></a> for submission deadline and reviewing timeline.
    </p>
  <p>
    Reviewing is <b>double blind</b> - remember to remove your names and affiliations in the submitted version (selecting the reviewing option in the LaTeX template will take care of that). Accepted works will be published in the CVPR 2024 workshop proceedings.
    </p>

<p><a href="https://cmt3.research.microsoft.com/AI4Space2024/"><b>To the submission site.</b></a></p>
    
  </div>
</div>

<div class="row" id="challenge">
<hr>
<br>
</div>

<div class="row">
  <div class="col-xs-12">
    <h2>SPARK2024</h2>
  </div>
</div>

<p>We are excited to co-host an AI for space challenge, SPARK 2024, which follows from the successful previous editions of the event at AI4Space @ ECCV 2022. The latest edition of SPARK (SPAcecraft Recognition leveraging Knowledge of Space Environment) aims to design data-driven approaches for spacecraft detection and trajectory estimation. SPARK will utilise data synthetically simulated with a game-based engine in addition to data collected from the Zero-G lab at the University of Luxembourg.</p>

<p>This year’s competition will include two streams:
<ul>
  <li>Stream-1: Detecting space objects in RGB images.</li>
  <li>Stream-2: Spacecraft trajectory estimation in a rendezvous scenario.</li>
</ul>
The datasets involved are larger and more diverse than that used in previous editions. For more information on the competition, including timelines, datasets, and submission details, please visit the <a href="https://cvi2.uni.lu/spark2024/">SPARK 2024 website</a>.</p>
      
<p>Final results and awards will be announced at AI4Space at CVPR 2024. Challenge winners may also be invited to present their methods at the workshop (subject to time availability in the finalised workshop program).</p>

<p><a href="https://cvi2.uni.lu/spark2024/"><b>To the challenge!</b></a></p>
  
<div class="row" id="dates">
<hr>
<br>
</div>

<div class="row">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
    All times/dates below are in Pacific Standard Time (PST).
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td><del>March 1</del> March 8, 2024</td>
        </tr>
        <tr>
          <td>Paper Reviewing Starts</td>
          <td><del>March 6</del> March 13, 2024</td>
        </tr>
        <tr>
          <td>Paper Reviews Due</td>
          <td><del>March 27</del> April 3, 2024</td>
        </tr>
        <tr>
          <td>Paper Decisions</td>
          <td><del>April 3</del> April 10, 2024</td>
        </tr>
        <tr>
          <td>Camera-Ready Deadline</td>
          <td>April 14, 2024</td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>June 17, 2024</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="row" id="program">
<hr>
<br>
</div>

<div class="row" id="program">
  <div class="col-xs-12">
    <h2>Workshop Program</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <!-- <h3>Block A</h3> -->
    <table class="table table-striped">
      <tbody>
        <tr>
            <th>Time (Pacific Daylight Time)</th>
            <th>Activity</th>
        </tr>
        <tr>
          <td>09:00 am</td>
          <td>Welcome address + housekeeping</td>
        </tr>
        <tr>
          <td>09:05 am</td>
          <td>SPARK Challenge</td>
        </tr>
        <tr>
          <td>09:10 am</td>
          <td>Invited Speaker 1: <a href="#keynote">Soon-Jo Chung</a> <br>Title TBD</td>
        </tr>
        <tr>
          <td>09:35 am</td>
          <td>Spotlight presentations - <a href="#papers">list of papers and presentation time</a></td>
        </tr>
        <tr>
          <td>10:35 am</td>
          <td>Poster session + break</td>
        </tr>
        <tr>
          <td>11:30 am</td>
          <td>Invited Speaker 2: <a href="#keynote">Gianluca Furano</a> <br>Title TBD</td>
        </tr>
        <tr>
          <td>11:55 am</td>
          <td>Award ceremony and wrap-up</td>
        </tr>
        <tr>
          <td>12:10 pm</td>
          <td>End</td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>

<div class="row" id="keynote">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
    <br>
  </div>
</div>

<!-- 26 -->
<div class="row">
  <div class="col-md-12" id="Soon-Jo">
    <a href="https://www.eas.caltech.edu/people/sjchung"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/soon-jo.png" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://www.eas.caltech.edu/people/sjchung">Soon-Jo Chung</a></b> is Bren Professor of Control and Dynamical Systems in the California Institute of Technology. Prof. Chung is also a Senior Research Scientist of the Jet Propulsion Laboratory, which Caltech manages for NASA. He is the recipient of the University of Illinois Engineering Dean’s Award for Excellence in Research, the Arnold Beckman Faculty Fellowship of the University of Illinois Center for Advanced Study, the AFOSR Young Investigator Program (YIP) award, the NSF CAREER award, a 2020 Honorable Mention for the IEEE Robotics and Automation Letters Best Paper Award, three best conference paper awards, including the AIAA Guidance, Navigation, and Control Conference and AIAA InfoTech, and five best student paper awards. Prof. Chung is an Associate Editor of the IEEE Transactions on Automatic Control and the AIAA Journal of Guidance, Control, and Dynamics. He was an Associate Editor of the IEEE Transactions on Robotics, and the Guest Editor of a Special Section on Aerial Swarm Robotics published in the IEEE Transactions on Robotics.
    </p>
  </div>
</div><br>

<!-- 24 -->
<div class="row">
  <div class="col-md-12" id="Gianluca">
    <a href="https://connectivity.esa.int/contacts/gianluca-furano"><img class="people-pic-big" style="float:left;margin-right:30px;" src="{{ "/static/img/speakers/gianluca.jpeg" | prepend:site.baseurl }}"></a>
    <p>
      <b><a href="https://connectivity.esa.int/contacts/gianluca-furano">Gianluca Furano</a></b> received the Ph.D. in microelectronics engineering from University of Rome and since 2003 works for the European Space Agency’s Data System Division, Noordwijk, The Netherlands. He is in charge of research and development activities and he coordinates European Space Agency (ESA) activities on on-board artificial intelligence. He has authored or coauthored more than 100 publications. Among his interests in ESA are on-board data handling systems and their major components, such as space grade microprocessors and support electronics, meeting very stringent requirements in terms of radiation tolerance, reliability, availability, and safety; key avionics building blocks such as platform mass memories, remote terminal units, on-board buses, and data networks; and on-board and space to ground data communication protocols including protocol security aspects. He also provides support to European Standardization Consultative Committee for Space Data Systems (CCSDS) and European Cooperation for Space Standardization (ECSS) in areas such as telemetry, telecommand and on-board data, and wireless and
monitoring control interfaces.
    </p>
  </div>
</div><br>

<div class="row" id="papers">
  <hr>
  <br>
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>

    <p>
    Each paper will be presented as a spotlight (<b>strictly 4 minutes presentation, plus 1 minute buffer for changover</b>).
    </p>
    
    <table class="table table-striped" id="sl1">
      <tbody>
        <tr>
          <th>
          Spotlight presentation time
          </th>
          <th>
          Paper title and authors
          </th>        
        </tr>
        <tr>
          <td>
          9:35 am <br> 
          </td>
          <td>
          Robust Perspective-n-Crater for Crater-based Camera Pose Estimation
          <br><em>Sofia A McLeod (University of Adelaide); Chee Kheng Chng (The University of Adelaide); Tatsuharu Ono (Hokkaido University); Yuta Shimizu (The University of Tokyo); Ryodo Hemmi (JAXA); Lachlan Holden (The University of Adelaide); Matthew Rodda (The University of Adelaide); Feras Dayoub (The University of Adelaide); Hirdy Miyamoto (University of Tokyo); Yukihiro Takahashi (Hokkaido University); Yasko Kasai (Tokyo Institute of Technology); Tat-Jun Chin (The University of Adelaide)</em>
          </td>
        </tr>
        <tr>
          <td>
          9:40 am <br> 
          </td>
          <td>Exploring AI-based satellite pose estimation: from novel synthetic dataset to in-depth performance evaluation
          <br><em>Thomas Chambon (IRT Saint-Exupery); Fabien FG Gallet (IRT Saint Exupery); Christophe Marabotto (IRT Saint-Exupery)</em>
          </td>
        </tr>
        <tr>
          <td>
          9:45 am <br> 
          </td>
          <td>Optimized Martian Dust Displacement Detection Using Explainable Machine Learning
          <br><em>Ana Lomashvili (DLR); Kristin Rammelkamp (DLR); Protim Bhattacharjee (DLR)</em>
          </td>
        </tr>
        <tr>
          <td>
          9:50 am <br> 
          </td>
          <td>Mitigating Challenges of the Space Environment for Onboard Artificial Intelligence: Design Overview for a recently launched payload
          <br><em>Miguel Ortiz del Castillo (University of Melbourne); Jonathan Morgan (University of Melbourne); Jack McRobbie (University of Melbourne	); Clint Therakam (University of Melbourne); Zaher Joukhadar (The University of Melbourne); Robert Mearns (University of Melbourne); Simon Barraclough (University of Melbourne); Richard Sinnott (University of Melbourne); Andrew Woods (University of Melbourne); Chris Bayliss (University of Melbourne); Krista A. Ehinger (University of Melbourne); Benjamin Rubinstein (University of Melbourne); James Bailey (University of Melbourne); Airlie Chapman (University of Melbourne); Michele Trenti (University of Melbourne)</em>
          </td>
        </tr>
        <tr>
          <td>
          9:55 am <br> 
          </td>
          <td>A Dual-Mode Approach for Vision-Based Navigation in a Lunar Landing Scenario
          <br><em>Roberto Del Prete (University of Naples "Federico II"); Luca Ostrogovich (University of Naples "Federico II"); Nicolas Longepe (ESA); Alfredo Renga (University of Naples "Federico II"); Giuseppe  Tomasicchio (Telespazio Spa)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:00 am <br> 
          </td>
          <td>Tackling the Satellite Downlink Bottleneck with Federated Onboard Learning of Image Compression
          <br><em>Gabriele Meoni (TU Delft); Pablo Gómez (European Space Agency)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:05 am <br> 
          </td>
          <td>Transformers for Orbit Determination Anomaly Detection and Classification
          <br><em>Nathan P Ré (Advanced Space, LLC); Matthew Popplewell (Advanced Space, LLC); Michael Caudill (Advanced Space, LLC); Tim Sullivan (Advanced Space, LLC); Tyler Hanf (Advanced Space, LLC); Benjamin Tatman (Advanced Space, LLC); Kanak Parmar (Advanced Space); Tyler Presser (Advanced Space, LLC); Sai Chikine (Advanced Space, LLC); Michael Grant (Advanced Space, LLC); Richard Poulson (Advanced Space, LLC)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:10 am <br> 
          </td>
          <td>Deploying Machine Learning Anomaly Detection Models to Flight Ready AI Boards
          <br><em>James Murphy (Réaltra Space Systems Engineering); Maria Buckley (Ubotica Technologies); Léonie Buckley (Ubotica Technologies); Adam Taylor (Adiuvo Engineering & Training); Jake O'Brien (Réaltra Space Systems Engineering); Brian Mac Namee (University College Dublin)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:15 am <br> 
          </td>
          <td>Cross-Temporal Spectrogram Autoencoder (CTSAE): Unsupervised Dimensionality Reduction for Clustering Gravitational Wave Glitches
          <br><em>Yi Li (Northwestern University); Yunan Wu (Northwestern University); Aggelos katsaggelos (Northwestern University)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:20 am <br> 
          </td>
          <td>Monocular 6-DoF Pose Estimation of Spacecrafts Utilizing Self-iterative Optimization and Motion Consistency
          <br><em>YunFeng Zhang (Academy of Mathematics and Systems Sciences, Chinese Academy of Sciences); Linjing You (Institute of Automation, Chinese Academy of Sciences); luyu yang (Institute of Automation Chinese Academy of Sciences); Zhiwei Zhang (Institute of Automation Chinese Academy of Sciences); Xiangli Nie (Institute of Automation, Chinese Academy of Sciences); Bo Zhang (Institute of Applied Mathematics, AMSS, Chinese Academy of Sciences)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:25 am <br> 
          </td>
          <td>CroSpace6D: Leveraging Geometric and Motion Cues for High-Precision Cross-Domain 6DoF Pose Estimation for Non-Cooperative Spacecrafts
          <br><em>Zuo Jianhong (Nanjing University of Aeronautics and Astronautics); Shengyang Zhang (University of Chinese Academy of Sciences); Qianyu Zhang (Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences); Zhao Yutao (Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences); Liu Baichuan (	Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences); Aodi Wu (University of Chinese Academy of Sciences); xue wan (Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences); Leizheng Shu (Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences); Kang Guohua (	Nanjing University of Aeronautics and Astronautics)</em>
          </td>
        </tr>
        <tr>
          <td>
          10:30 am <br> 
          </td>
          <td>Revisiting the Domain Gap Issue in Non-cooperative Spacecraft Pose Tracking
          <br><em>Kun Liu (Nanjing university of science and technology); Yongjun Yu (Nanjing university of science and technology)</em>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="row" id="people">
<hr>
<br>
</div>

<div class="row">
  <div class="col-xs-12">
    <h2>Organisers</h2>
  </div>
</div>

<div class="row">

  <div class="col-xs-3 col-sm-3">
    <a href="https://cs.adelaide.edu.au/~ssl/">
      <img class="people-pic" src="{{ "/static/img/people/tj.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://cs.adelaide.edu.au/~ssl">Tat-Jun Chin</a>
      <h6>The University of Adelaide</h6>
    </div>
  </div>

  <div class="col-xs-3 col-sm-3">
    <a href="https://www.tudelft.nl/en/staff/g.meoni/?cHash=50c2ee0e3039113d27bb27926ef88e27">
      <img class="people-pic" src="{{ "/static/img/people/gabriele.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.tudelft.nl/en/staff/g.meoni/?cHash=50c2ee0e3039113d27bb27926ef88e27">Gabriele Meoni</a>
      <h6>TU Delft</h6>
    </div>
  </div>

  <div class="col-xs-3 col-sm-3">
    <a href="https://cvi2.uni.lu//">
      <img class="people-pic" src="{{ "/static/img/people/djamila.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://cvi2.uni.lu/">Djamila Aouada</a>
      <h6>University of Luxembourg</h6>
    </div>
  </div>

  <div class="col-xs-3 col-sm-3">
    <a href="https://slab.stanford.edu/people/jeff-park">
      <img class="people-pic" src="{{ "/static/img/people/jeff.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://slab.stanford.edu/people/jeff-park">Tae Ha "Jeff" Park</a>
      <h6>Stanford’s Space Rendezvous Lab</h6>
    </div>
  </div>

  </div>

  <div class="row">

  <div class="col-xs-3 col-sm-3">
    <a href="https://www.rajattalak.com/">
      <img class="people-pic" src="{{ "/static/img/people/rajat.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.rajattalak.com/">Rajat Talak</a>
      <h6>MIT</h6>
    </div>
  </div>

  <div class="col-xs-3 col-sm-3">
    <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/viorela-ila.html">
      <img class="people-pic" src="{{ "/static/img/people/viorela.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/viorela-ila.html">Viorela Ila</a>
      <h6>The University of Sydney</h6>
    </div>
  </div>

  <div class="col-xs-3 col-sm-3">
    <a href="https://it.linkedin.com/in/nicolaslongepe/en">
      <img class="people-pic" src="{{ "/static/img/people/nicolas.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://it.linkedin.com/in/nicolaslongepe/en">Nicolas Long&eacute;p&eacute;</a>
      <h6>European Space Agency</h6>
    </div>
  </div>   

  <div class="col-xs-3 col-sm-3">
    <a href="https://cvi2.uni.lu/">
      <img class="people-pic" src="{{ "/static/img/people/arunkumar.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://cvi2.uni.lu/">Arunkumar Rathinam</a>
      <h6>University of Luxembourg</h6>
    </div>
  </div>   

</div>

<div class="row">
  <div class="col-md-12">
    <h2>Program Committee</h2>
    <p>
    <ul>
<li>Alexander Hadjiivanov, European Space Agency</li>
<li>Andrew L Price, École Polytechnique Fédérale de Lausanne</li>
<li>Anis Kacem, SnT, University of Luxembourg</li>
<li>Artur Nowakowski, European Space Agency</li>
<li>Chee Kheng Chng, The University of Adelaide</li>
<li>David Rijlaarsdam, Ubotica Technologies</li>
<li>Dominic	R Maggio, MIT</li>
<li>Enjie Ghorbel, CRISTAL, ENSI, University of Manouba</li>
<li>Ethan Elms, University of Adelaide</li>
<li>Evridiki Ntagiou, European Space Agency</li>
<li>Florent Lafarge, INRIA</li>
<li>Giovanni Beltrame, Polytechnique Montreal</li>
<li>Giulia Ciabatti, Sapienza, University of Rome</li>
<li>Huangying Zhan,	InnoPeak Technology</li>
<li>Inder Pal Singh, University of Luxembourg</li>
<li>Jingnan Shi, MIT</li>
<li>Jose A Sosa Martinez, University of Luxembourg</li>
<li>José Luis Espinosa-Aranda, Ubotica Technologies</li>
<li>Juan Ignacio Bravo, Deimos Space, Universidad Autónoma de Madrid</li>
<li>Juan Jose Garau Luis, InstaDeep</li>
<li>Kapil Mirchandani, Pune Institute of Computer Technology</li>
<li>Kyongsik Yun, California Institute of Technology</li>
<li>Leo Pauly, University of Luxembourg</li>
<li>Lorenzo	Giusti, CERN</li>
<li>Lorenzo	F Shaikewitz, MIT</li>
<li>Manuel Salvoldi, Ben-Gurion University of the Negev</li>
<li>Marcus Maertens, European Space Agency</li>
<li>Marie Farrell, University of Manchester</li>
<li>Mehregan Dor, Georgia Institute of Technology</li>
<li>Michele Sasdelli, The University of Adelaide</li>	
<li>Mohamed Adel Musallam, SnT</li>			
<li>Mohsi Jawaid, The University of Adelaide</li>
<li>Padmaja Jonnalagedda, UC Riverside</li>
<li>R. Michael Swan, NASA JPL</li>
<li>Roberto	Del Prete, University of Naples "Federico II"</li>
<li>Roy E Prouty, UMBC</li>
<li>Shirley	Ho, Flatiron Institute</li>
<li>Shreyansh Daftry, JPL</li>
<li>Sofia A McLeod, University of Adelaide</li>
<li>Somrita Banerjee, Stanford University</li>
<li>Tae Ha Park, Stanford University</li>
<li>Vincent Gaudilliere, SnT</li>
<li>Xiaobiao Du, University of Technology Sydney</li>
<li>Yasir Latif, The University of Adelaide</li>
    </ul>
    </p>
  </div>
</div>

<div class="row" id="sponsors">
<hr>
<br>
</div>

<div class="row">
  <div class="col-xs-12">
    <h2>Sponsors</h2>
    <br>
  </div>
</div>


<p>TBD</p>

<div class="row">
<hr>
<br>
</div>
